{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b9e666-51a7-4d74-af3f-097b613100dd",
   "metadata": {},
   "source": [
    "## Training a Masked Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8753c102-5299-492f-a620-ce3bbbb7d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from time import time\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from gaiaxpy import generate, PhotometricSystem\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.rcParams['xtick.major.size'] = 5.0\n",
    "plt.rcParams['xtick.minor.size'] = 3.0\n",
    "plt.rcParams['ytick.major.size'] = 5.0\n",
    "plt.rcParams['ytick.minor.size'] = 3.0\n",
    "plt.rcParams['xtick.top'] = True\n",
    "plt.rcParams['ytick.right'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b3b90-6b10-4371-915b-e53eea83e19e",
   "metadata": {},
   "source": [
    "Converting to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a2ad50-1678-475c-9fd9-6816409c005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dfe9eb-9235-4bd0-808c-f4cf267d12d5",
   "metadata": {},
   "source": [
    "Checking directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0499d6-8684-459c-9d47-9e6ac3d8d7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /scratch/\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8731b87-ad6e-4b5b-bdf0-6fdff9bda93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalers for dataloading\n",
    "metscaler = StandardScaler(); logscaler = StandardScaler(); tefscaler = StandardScaler()\n",
    "# extscaler = StandardScaler(); parscaler = StandardScaler()\n",
    "scale = 'standard_scale'\n",
    "\n",
    "batchlen = 32\n",
    "lr = 1e-4\n",
    "epochs = 10\n",
    "optimize = 'Adam'\n",
    "datafname = \"/arc/home/aydanmckay/mae_tab/lamost_pristine_bprp_gmag.h5\"\n",
    "datashort = 'ViT_MAE_v1'\n",
    "lossname = 'L2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39544205-8c90-441f-a866-44750d5bb643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining the Dataset class\n",
    "class data_set(Dataset):\n",
    "    '''\n",
    "    Main way to access the .h5 file.\n",
    "    '''\n",
    "    def __init__(self,file,train=True,valid=False,test=False,noscale=False):\n",
    "        fn = h5py.File(file, 'r')\n",
    "        self.f = fn\n",
    "        \n",
    "        # get data\n",
    "        if train:\n",
    "            name = 'group_1'\n",
    "        elif valid:\n",
    "            name = 'group_2'\n",
    "        elif test or noscale:\n",
    "            name = 'group_3'\n",
    "        \n",
    "        dset = self.f[name]['theta']\n",
    "        dl = dset[:]\n",
    "        if noscale:\n",
    "            self.l = dl.shape[1]\n",
    "            self.t = torch.Tensor(dl.T)\n",
    "        else:\n",
    "            dat = np.array([\n",
    "                metscaler.fit_transform(dl[[0]].T).flatten(),\n",
    "                logscaler.fit_transform(dl[[1]].T).flatten(),\n",
    "                tefscaler.fit_transform(dl[[2]].T).flatten(),\n",
    "            ])\n",
    "            self.l = dat.shape[1]\n",
    "            self.x = torch.Tensor(dat.T)\n",
    "\n",
    "        ydset = self.f[name]['bprp']\n",
    "        ydat = ydset[:]\n",
    "        self.y = torch.Tensor(ydat[:].T)\n",
    "\n",
    "        errdset = self.f[name]['e_bprp']\n",
    "        self.err = torch.Tensor(errdset[:].T)\n",
    "        \n",
    "        mdset = self.f[name]['mags']\n",
    "        self.m = torch.Tensor(mdset[:].T)\n",
    "        \n",
    "        ddset = self.f[name]['dist']\n",
    "        self.d = torch.Tensor(ddset[:].T)\n",
    "        \n",
    "        edset = self.f[name]['ext']\n",
    "        self.e = torch.Tensor(edset[:].T)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.l\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        tg = self.t[index]\n",
    "        yg = self.y[index]\n",
    "        mg = self.m[index]\n",
    "        errg = self.err[index]\n",
    "        eg = self.e[index]\n",
    "        dg = self.d[index]\n",
    "        return (tg,yg,errg,mg,eg,dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434947fd-bf47-4e8f-b59e-68533cc230f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE from chatgpt\n",
    "# switch encoder for above tab_vit\n",
    "class MaskedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, mask):\n",
    "        super(MaskedAutoencoder, self).__init__()\n",
    "        self.mask = torch.tensor(mask, dtype=torch.float32)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        masked_x = x * self.mask\n",
    "        z = self.encoder(masked_x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac4d5e1e-f866-4176-b58e-22a35e8fefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data_set(datafname)\n",
    "valid_data = data_set(datafname,train=False,valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ba5b7ec-3c42-404a-ab87-43abea670c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    training_data,\n",
    "    batch_size=batchlen,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=batchlen,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9be5412-c330-4ee2-b7f6-3d12fa466df1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMAE\u001b[49m()\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MAE' is not defined"
     ]
    }
   ],
   "source": [
    "model = MAE()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578d418-309e-4ac3-8461-6463232260c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    '''\n",
    "    The autoencoder to be used to reduce the images of the galaxies down\n",
    "    to a latent space, from which the original images are to be reconstructed.\n",
    "    The improvements are as follows: using both batch normalization and maxpool\n",
    "    layers in the encoder, having a better decoder output layer, in which the\n",
    "    kernel size is not large, having a MLP in the model, so that the algorithm\n",
    "    can train on both reconstruction error and prediction error simultaneously.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # The encoder, reducing the images down from a shape of (batchsize, 3, 200, 200)\n",
    "        # to a shape of (batchsize, 1024)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1), # shape (batchsize, 16, 200, 200)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2, stride=2), # shape (batchsize, 16, 100, 100)\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # shape (batchsize, 32, 100, 100)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, stride=2), # shape (batchsize, 32, 50, 50)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # shape (batchsize, 64, 50, 50)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, stride=2), # shape (batchsize, 64, 25, 25)\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # shape (batchsize, 128, 25, 25)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, stride=2), # shape (batchsize, 128, 12, 12)\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),# shape (batchsize, 256, 12, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, stride=2), # shape (batchsize, 256, 6, 6)\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),# shape (batchsize, 512, 6, 6)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(2, stride=2), # shape (batchsize, 512, 3, 3)\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),# shape (batchsize, 1024, 3, 3)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.MaxPool2d(2, stride=2), # shape (batchsize, 1024, 1, 1)\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 1024)\n",
    "        )\n",
    "        # the decoder, reconstucting the images to the original shape of (batchsize, 3, 424, 424)\n",
    "        # from the latent vector of 1024\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(-1, (1024, 1, 1)),\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1, output_padding=1), # shape (batchsize, 512, 3, 3)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1), # shape (batchsize, 256, 6, 6)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # shape (batchsize, 128, 12, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, output_padding=1), # shape (batchsize, 64, 25, 25)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1), # shape (batchsize, 32, 50, 50)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1), # shape (batchsize, 16, 100, 100)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1), # shape (batchsize, 3, 200, 200)\n",
    "            # nn.Sigmoid(),\n",
    "        )\n",
    "        # the classifier, a simple 3-layer MLP to predict the morphology of the galaxies\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(1024, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            # sigmoid to make predictions in between 0 and 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the forward function, encoding then decoding the data\n",
    "        # and predicting from the latent space\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        predicted = self.mlp(encoded)\n",
    "        return (decoded,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea1135-8504-4539-9e90-3fd33069cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the hyperparameters\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# initializing the autoencoder\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "# setting the optimization algorithm\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# defining the reconstruction loss function\n",
    "recon_loss = nn.MSELoss()\n",
    "\n",
    "# defining the prediction loss function (binary output)\n",
    "pred_loss = nn.BCELoss()\n",
    "\n",
    "# defining new training and validation functions\n",
    "def newtrain(model, dataloader, recon_loss, pred_loss, optimizer):\n",
    "    '''\n",
    "    The training algorithm of the autoencoder. This algorithm now\n",
    "    combines the losses of both reconstruction and prediction to\n",
    "    train both simultaneously.\n",
    "    '''\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    running_recon_loss = 0.0\n",
    "    running_pred_loss = 0.0\n",
    "    for batch_imgs,y in dataloader:\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # predicting\n",
    "        outputs,preds = model(batch_imgs)\n",
    "\n",
    "        # computing the individual losses\n",
    "        recon_error = recon_loss(outputs, batch_imgs)\n",
    "        pred_error = pred_loss(preds,y.reshape(-1,1).float())\n",
    "\n",
    "        # computing the total loss\n",
    "        loss = recon_error + pred_error\n",
    "\n",
    "        # backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # updating the running loss\n",
    "        running_recon_loss += recon_error.item() * batch_imgs.size(0)\n",
    "        running_pred_loss += pred_error.item() * batch_imgs.size(0)\n",
    "        train_loss += loss.item() * batch_imgs.size(0)\n",
    "\n",
    "    # printing the two losses separately\n",
    "    print(\"Epoch %d Reconstruction Loss: %.3f Prediction Loss: %.3f\" % (epoch+1,running_recon_loss/len(dataloader.dataset),running_pred_loss/len(dataloader.dataset)))\n",
    "    return train_loss / len(dataloader.dataset)\n",
    "\n",
    "def newvalidate(model, dataloader, recon_loss, pred_loss):\n",
    "    '''\n",
    "    The validation algorithm for the autoencoder. Similar to the\n",
    "    training algorithm function, the diffence is that backprop and\n",
    "    optimization is not done during the evaluation step.\n",
    "    '''\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_imgs,y in dataloader:\n",
    "            y = y.to(device)\n",
    "\n",
    "            # predicting\n",
    "            outputs,preds = model(batch_imgs)\n",
    "\n",
    "            # computing the losses\n",
    "            recon_error = recon_loss(outputs, batch_imgs)\n",
    "            pred_error = pred_loss(preds,y.reshape(-1,1).float())\n",
    "\n",
    "            # computing the total loss\n",
    "            loss = recon_error + pred_error\n",
    "            val_loss += loss.item() * batch_imgs.size(0)\n",
    "    return val_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a4525-d340-4e2c-93e4-d311304adb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the algorithm\n",
    "ntlosses = []\n",
    "nvlosses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = newtrain(net, new_train_loader, recon_loss, pred_loss, optimizer)\n",
    "    val_loss = newvalidate(net, new_val_loader, recon_loss, pred_loss)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
    "    ntlosses.append(train_loss)\n",
    "    nvlosses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f03f2f-07da-4186-b505-a769276fa3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the loss\n",
    "plt.plot(range(1,num_epochs+1),ntlosses,label='Train Loss')\n",
    "plt.plot(range(1,num_epochs+1),nvlosses,label='Valid Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Combined Loss')\n",
    "plt.legend(fancybox=True)\n",
    "# plt.savefig('/content/drive/MyDrive/lossplotnet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d75649-6a5f-41cc-b685-3fc788df53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the new algorithm\n",
    "# torch.save(net.state_dict(), '/content/drive/MyDrive/gpumodel2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188594b7-ff2a-4aa8-b082-423a9a937f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the new algorithm\n",
    "net.load_state_dict(torch.load('/content/drive/MyDrive/gpumodel2.pth'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b38227-0713-467d-9a43-31029153d1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
