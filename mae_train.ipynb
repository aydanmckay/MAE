{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b9e666-51a7-4d74-af3f-097b613100dd",
   "metadata": {},
   "source": [
    "## Training a Masked Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8753c102-5299-492f-a620-ce3bbbb7d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.rcParams['xtick.major.size'] = 5.0\n",
    "plt.rcParams['xtick.minor.size'] = 3.0\n",
    "plt.rcParams['ytick.major.size'] = 5.0\n",
    "plt.rcParams['ytick.minor.size'] = 3.0\n",
    "plt.rcParams['xtick.top'] = True\n",
    "plt.rcParams['ytick.right'] = True\n",
    "from time import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from gaiaxpy import generate, PhotometricSystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b3b90-6b10-4371-915b-e53eea83e19e",
   "metadata": {},
   "source": [
    "Converting to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a2ad50-1678-475c-9fd9-6816409c005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dfe9eb-9235-4bd0-808c-f4cf267d12d5",
   "metadata": {},
   "source": [
    "Checking directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0499d6-8684-459c-9d47-9e6ac3d8d7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /scratch/\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39544205-8c90-441f-a866-44750d5bb643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining the Dataset class\n",
    "class data_set(Dataset):\n",
    "    '''\n",
    "    Main way to access the .h5 file.\n",
    "    '''\n",
    "    def __init__(self,file,train=True,valid=False,test=False,noscale=False):\n",
    "        fn = h5py.File(file, 'r')\n",
    "        self.f = fn\n",
    "        \n",
    "        # get data\n",
    "        if train:\n",
    "            dset = self.f['group_1']['data']\n",
    "            d = dset[:]\n",
    "            dat = np.array([\n",
    "                metscaler.fit_transform(d[[0]].T).flatten(),\n",
    "                logscaler.fit_transform(d[[1]].T).flatten(),\n",
    "                tefscaler.fit_transform(d[[2]].T).flatten(),\n",
    "                amscaler.fit_transform(d[[3]].T).flatten(), # comment out if not\n",
    "            ])\n",
    "            self.l = dat.shape[1]\n",
    "            self.x = torch.Tensor(dat.T)\n",
    "        elif valid:\n",
    "            dset = self.f['group_2']['data']\n",
    "            d = dset[:]\n",
    "            dat = np.array([\n",
    "                metscaler.transform(d[[0]].T).flatten(),\n",
    "                logscaler.transform(d[[1]].T).flatten(),\n",
    "                tefscaler.transform(d[[2]].T).flatten(),\n",
    "                amscaler.transform(d[[3]].T).flatten(), # comment out if not\n",
    "            ])\n",
    "            self.l = dat.shape[1]\n",
    "            self.x = torch.Tensor(dat.T)\n",
    "        elif test:\n",
    "            dset = self.f['group_3']['data']\n",
    "            d = dset[:]\n",
    "            dat = np.array([\n",
    "                metscaler.transform(d[[0]].T).flatten(),\n",
    "                logscaler.transform(d[[1]].T).flatten(),\n",
    "                tefscaler.transform(d[[2]].T).flatten(),\n",
    "                amscaler.transform(d[[3]].T).flatten(), # comment out if not\n",
    "            ])\n",
    "            self.l = dat.shape[1]\n",
    "            self.x = torch.Tensor(dat.T)\n",
    "        elif noscale:\n",
    "            dset = self.f['group_3']['data']\n",
    "            d = dset[:]\n",
    "            self.l = d.shape[1]\n",
    "            self.x = torch.Tensor(d.T)\n",
    "        \n",
    "        # get label\n",
    "        if train:\n",
    "            ydset = self.f['group_1']['label']\n",
    "            ydat = ydset[:]\n",
    "            self.y = torch.Tensor(ydat[:].T) # torch.from_numpy(y[index]) does not work since y is doubles and not floats.\n",
    "        elif valid:\n",
    "            ydset = self.f['group_2']['label']\n",
    "            ydat = ydset[:]\n",
    "            self.y = torch.Tensor(ydat[:].T)\n",
    "        elif test:\n",
    "            ydset = self.f['group_3']['label']\n",
    "            ydat = ydset[:]\n",
    "            self.y = torch.Tensor(ydat[:].T)\n",
    "        elif noscale:\n",
    "            ydset = self.f['group_3']['label']\n",
    "            ydat = ydset[:]\n",
    "            self.y = torch.Tensor(ydat.T)\n",
    "        \n",
    "        # get error in label # comment out for non-error label runs\n",
    "        if train:\n",
    "            errdset = self.f['group_1']['e_label']\n",
    "            self.err = torch.Tensor(errdset[:].T)\n",
    "        elif valid:\n",
    "            errdset = self.f['group_2']['e_label']\n",
    "            self.err = torch.Tensor(errdset[:].T)\n",
    "        elif test or noscale:\n",
    "            errdset = self.f['group_3']['e_label']\n",
    "            self.err = torch.Tensor(errdset[:].T)\n",
    "            \n",
    "        if train:\n",
    "            gdset = self.f['group_1']['gmag']\n",
    "            self.g = torch.Tensor(gdset[:].T)\n",
    "        elif valid:\n",
    "            gdset = self.f['group_2']['gmag']\n",
    "            self.g = torch.Tensor(gdset[:].T)\n",
    "        elif test or noscale:\n",
    "            gdset = self.f['group_3']['gmag']\n",
    "            self.g = torch.Tensor(gdset[:].T)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.l\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        xg = self.x[index]\n",
    "        yg = self.y[index]\n",
    "        gg = self.g[index]\n",
    "        errg = self.err[index]\n",
    "        return (xg,yg,gg,errg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d5e1e-f866-4176-b58e-22a35e8fefe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba5b7ec-3c42-404a-ab87-43abea670c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be5412-c330-4ee2-b7f6-3d12fa466df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adea164b-8f9e-405e-bdd6-5503675f2af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chatgpt TabularViT\n",
    "# this will be the encoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# Define the TabularViT model\n",
    "class TabularViT(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, patch_dim=64, num_patches=16, dim=256, depth=6, heads=8, mlp_dim=512):\n",
    "        super().__init__()\n",
    "        self.patch_dim = patch_dim\n",
    "        self.num_patches = num_patches\n",
    "        self.to_patch_embedding = nn.Linear(input_dim, patch_dim)\n",
    "        self.position_embeddings = nn.Parameter(torch.zeros(1, num_patches + 1, dim))\n",
    "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=mlp_dim), num_layers=depth)\n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "        self.fc = nn.Linear(dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.to_patch_embedding(x).transpose(1, 2)\n",
    "        x = self._add_positional_encoding(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.layer_norm(x.mean(dim=1))\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def _add_positional_encoding(self, x):\n",
    "        b, n, _ = x.shape\n",
    "        position_embeddings = self.position_embeddings[:, :(n + 1)]\n",
    "        return (x + position_embeddings).permute(1, 0, 2)\n",
    "\n",
    "# Define the TabularDataset class to load the data\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Load the data and split into train and validation sets\n",
    "# data = pd.read_csv('data.csv')\n",
    "# X = data.drop(columns=['target'])\n",
    "# y = data['target']\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create the data loaders\n",
    "# train_dataset = TabularDataset(X_train.values, y_train.values)\n",
    "# val_dataset = TabularDataset(X_val.values, y_val.values)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the training loop\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    accuracy = 100.0 * correct / len(train_loader.dataset)\n",
    "\n",
    "    return train_loss, accuracy\n",
    "\n",
    "# Define the validation loop\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434947fd-bf47-4e8f-b59e-68533cc230f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE from chatgpt\n",
    "# switch encoder for above tab_vit\n",
    "class MaskedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, mask):\n",
    "        super(MaskedAutoencoder, self).__init__()\n",
    "        self.mask = torch.tensor(mask, dtype=torch.float32)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        masked_x = x * self.mask\n",
    "        z = self.encoder(masked_x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8df79-40ae-4bcd-8c5b-344ccab7ca8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
